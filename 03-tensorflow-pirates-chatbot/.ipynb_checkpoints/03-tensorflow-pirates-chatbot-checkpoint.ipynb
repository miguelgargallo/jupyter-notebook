{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/miguelgargallo/jupyter-notebook/blob/main/04-tensorflow-pirates-chatbot\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "fS1vkFst7IXH"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "2Iu-FC9y7eUs"
   },
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "with open('content.json') as content:\n",
    "  data1 = json.load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "Xw9WTif47fzL"
   },
   "outputs": [],
   "source": [
    "#getting all the data to lists\n",
    "tags = []\n",
    "inputs = []\n",
    "responses={}\n",
    "for intent in data1['intents']:\n",
    "  responses[intent['tag']]=intent['responses']\n",
    "  for lines in intent['input']:\n",
    "    inputs.append(lines)\n",
    "    tags.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "8pj3E2hc7hZB"
   },
   "outputs": [],
   "source": [
    "#converting to dataframe\n",
    "data = pd.DataFrame({\"inputs\":inputs,\n",
    "                     \"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "dBRR1ac67i6M",
    "outputId": "bb8ceece-ad22-4830-f43a-0524d6aeb3c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice to meet you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi, is this is the pirate's organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any pirates here ?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tell me more about the pre requisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>give more details about the pre-requisites</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>What are the requirements</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>what's the basic requirements</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>what are the basic skills to get recruited ?</td>\n",
       "      <td>prerequisites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          inputs           tags\n",
       "0                                          hello       greeting\n",
       "1                                       hi there       greeting\n",
       "2                               nice to meet you       greeting\n",
       "3       hi, is this is the pirate's organization       greeting\n",
       "4                             any pirates here ?       greeting\n",
       "..                                           ...            ...\n",
       "76         tell me more about the pre requisites  prerequisites\n",
       "77    give more details about the pre-requisites  prerequisites\n",
       "78                     What are the requirements  prerequisites\n",
       "79                 what's the basic requirements  prerequisites\n",
       "80  what are the basic skills to get recruited ?  prerequisites\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "GEWafJbl7k8m"
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Fmqo2OKC7mz_",
    "outputId": "e9d8f789-79d8-4689-f026-847f8e034079"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>okay i will see you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>your name</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>how to join the organization</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thanks</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>who are you</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>steps to join the pirates</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>see you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>what are you</td>\n",
       "      <td>whoareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>you are from where</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          inputs         tags\n",
       "25     okay i will see you later      goodbye\n",
       "43                    your name     whoareyou\n",
       "64  how to join the organization         join\n",
       "15                        thanks      goodbye\n",
       "38                  who are you     whoareyou\n",
       "..                           ...          ...\n",
       "5                             hi     greeting\n",
       "66     steps to join the pirates         join\n",
       "22                 see you later      goodbye\n",
       "39                 what are you     whoareyou\n",
       "55            you are from where  whereareyou\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations\n",
    "import string\n",
    "data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "dJisg3CL7oP9"
   },
   "outputs": [],
   "source": [
    "#tokenize the data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['inputs'])\n",
    "train = tokenizer.texts_to_sequences(data['inputs'])\n",
    "#apply padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(train)\n",
    "\n",
    "#encoding the outputs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "75wZdVHb7scG",
    "outputId": "d567315b-44b0-4fe5-b63c-86ae37e6abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "u0RjcluP7tvy",
    "outputId": "a579e666-e9ce-477a-a55a-b2a030788ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  96\n",
      "output length:  8\n"
     ]
    }
   ],
   "source": [
    "#define vocabulary\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words : \",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \",output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "4qPHjMAP7vF6"
   },
   "outputs": [],
   "source": [
    "#creating the model\n",
    "\n",
    "i = Input(shape=(input_shape,))\n",
    "x = Embedding(vocabulary+1,10)(i)\n",
    "x = LSTM(10,return_sequences=True)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(output_length,activation=\"softmax\")(x)\n",
    "model  = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "0o81iOME7wtD"
   },
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QgxknlTp7yM0",
    "outputId": "91e4a26a-8e31-43f6-8f43-e7e1b686f4e3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 14:18:46.413768: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-01-19 14:18:46.413966: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-01-19 14:18:46.427249: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-01-19 14:18:46.427443: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_5' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/usr/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/usr/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/usr/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40257/48579934.py\", line 2, in <module>\n      train = model.fit(x_train,y_train,epochs=200)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 532, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1163, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 639, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1189, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1239, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1234, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_5'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_5}}]] [Op:__inference_train_function_37457]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#training the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_5' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/usr/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/usr/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/usr/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/usr/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40257/48579934.py\", line 2, in <module>\n      train = model.fit(x_train,y_train,epochs=200)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 532, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1163, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 639, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1189, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1239, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/fengh/.local/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1234, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_5'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_5}}]] [Op:__inference_train_function_37457]"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "train = model.fit(x_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "un6J84498FkY",
    "outputId": "0d08acc0-1f6c-450b-f402-b56680de300b"
   },
   "outputs": [],
   "source": [
    "#plotting model accuracy\n",
    "plt.plot(train.history['accuracy'],label='training set accuracy')\n",
    "plt.plot(train.history['loss'],label='training set loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ny5HGpOJ8Ijg",
    "outputId": "c2757625-d1fc-4d4e-a5ea-e20ff691666c"
   },
   "outputs": [],
   "source": [
    "#chatting\n",
    "import random\n",
    "\n",
    "\n",
    "while True:\n",
    "  texts_p = []\n",
    "  prediction_input = input('You : ')\n",
    "\n",
    "  #removing punctuation and converting to lowercase\n",
    "  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "  prediction_input = ''.join(prediction_input)\n",
    "  texts_p.append(prediction_input)\n",
    "\n",
    "  #tokenizing and padding\n",
    "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "  prediction_input = np.array(prediction_input).reshape(-1)\n",
    "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "\n",
    "  #getting output from model\n",
    "  output = model.predict(prediction_input)\n",
    "  output = output.argmax()\n",
    "\n",
    "  #finding the right tag and predicting\n",
    "  response_tag = le.inverse_transform([output])[0]\n",
    "  print(\"Going Merry : \",random.choice(responses[response_tag]))\n",
    "  if response_tag == \"goodbye\":\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPE7dmy0nxfQeUOIf7hy3r7",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
